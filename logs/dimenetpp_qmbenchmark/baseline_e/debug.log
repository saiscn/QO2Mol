2024-12-24 11:52:17,595 - filelogger.py:78 - qDict{
	seed:377
	log_dir:logs/dimenetpp_qmbenchmark/baseline_e/
	print_freq:100
	config_file:logs/dimenetpp_qmbenchmark/baseline_e/config.yaml
	init_file:None
	task:qDict{
	data_key:None
	data_root:/root/proj/database/qm_benchmark
	target:energy
	regress_force:False
	standardize:True
	add_noise:False
	noise_params:None
	dataset:qm_benchmark
	}
	model:qDict{
	name:None
	num_blocks:4
	hidden_channels:128
	out_channels:1
	int_emb_size:64
	basis_emb_size:16
	out_emb_channels:256
	num_spherical:8
	num_radial:6
	envelope_exponent:5
	max_num_neighbors:32
	cutoff:5.0
	num_before_skip:1
	num_after_skip:2
	num_output_layers:3
	}
	dataloader:{'batch_size': 256, 'eval_batch_size': 256, 'num_workers': 8, 'pin_memory': True}
	optim:qDict{
	optimizer:AdamW
	optimizer_params:{'weight_decay': 0.0001}
	lr_initial:0.0008
	scheduler:LambdaLR
	scheduler_params:{'lambda_type': 'cosine', 'warmup_factor': 0.2, 'warmup_epochs': 0.01, 'lr_min_factor': 0.01}
	clip_grad_norm:10
	max_epochs:500
	energy_coefficient:1
	force_coefficient:20
	loss_energy:mae
	loss_force:mae
	ema:False
	ema_decay:0.999
	eval_every:5000
	}
	ckp_file:None
	test:False
	distributed:False
	rank:0
	device:cuda
	}
2024-12-24 11:53:56,983 - filelogger.py:78 - qDict{
	seed:377
	log_dir:logs/dimenetpp_qmbenchmark/baseline_e/
	print_freq:100
	config_file:logs/dimenetpp_qmbenchmark/baseline_e/config.yaml
	init_file:None
	task:qDict{
	data_key:None
	data_root:/root/proj/database/qm_benchmark
	target:energy
	regress_force:False
	standardize:True
	add_noise:False
	noise_params:None
	dataset:qm_benchmark
	}
	model:qDict{
	name:None
	num_blocks:4
	hidden_channels:128
	out_channels:1
	int_emb_size:64
	basis_emb_size:16
	out_emb_channels:256
	num_spherical:8
	num_radial:6
	envelope_exponent:5
	max_num_neighbors:32
	cutoff:5.0
	num_before_skip:1
	num_after_skip:2
	num_output_layers:3
	}
	dataloader:{'batch_size': 256, 'eval_batch_size': 256, 'num_workers': 8, 'pin_memory': True}
	optim:qDict{
	optimizer:AdamW
	optimizer_params:{'weight_decay': 0.0001}
	lr_initial:0.0008
	scheduler:LambdaLR
	scheduler_params:{'lambda_type': 'cosine', 'warmup_factor': 0.2, 'warmup_epochs': 0.01, 'lr_min_factor': 0.01}
	clip_grad_norm:10
	max_epochs:500
	energy_coefficient:1
	force_coefficient:20
	loss_energy:mae
	loss_force:mae
	ema:False
	ema_decay:0.999
	eval_every:5000
	}
	ckp_file:None
	test:False
	distributed:False
	rank:0
	device:cuda
	}
2024-12-24 11:54:20,249 - filelogger.py:78 - qDict{
	seed:377
	log_dir:logs/dimenetpp_qmbenchmark/baseline_e/
	print_freq:100
	config_file:logs/dimenetpp_qmbenchmark/baseline_e/config.yaml
	init_file:None
	task:qDict{
	data_key:None
	data_root:/root/proj/database/qm_benchmark
	target:energy
	regress_force:False
	standardize:True
	add_noise:False
	noise_params:None
	dataset:qm_benchmark
	}
	model:qDict{
	name:None
	num_blocks:4
	hidden_channels:128
	out_channels:1
	int_emb_size:64
	basis_emb_size:16
	out_emb_channels:256
	num_spherical:8
	num_radial:6
	envelope_exponent:5
	max_num_neighbors:32
	cutoff:5.0
	num_before_skip:1
	num_after_skip:2
	num_output_layers:3
	}
	dataloader:{'batch_size': 256, 'eval_batch_size': 256, 'num_workers': 8, 'pin_memory': True}
	optim:qDict{
	optimizer:AdamW
	optimizer_params:{'weight_decay': 0.0001}
	lr_initial:0.0008
	scheduler:LambdaLR
	scheduler_params:{'lambda_type': 'cosine', 'warmup_factor': 0.2, 'warmup_epochs': 0.01, 'lr_min_factor': 0.01}
	clip_grad_norm:10
	max_epochs:500
	energy_coefficient:1
	force_coefficient:20
	loss_energy:mae
	loss_force:mae
	ema:False
	ema_decay:0.999
	eval_every:5000
	}
	ckp_file:None
	test:False
	distributed:False
	rank:0
	device:cuda
	}
2024-12-24 11:54:52,198 - filelogger.py:78 - qDict{
	seed:377
	log_dir:logs/dimenetpp_qmbenchmark/baseline_e/
	print_freq:100
	config_file:logs/dimenetpp_qmbenchmark/baseline_e/config.yaml
	init_file:None
	task:qDict{
	data_key:None
	data_root:/root/proj/database/qm_benchmark
	target:energy
	regress_force:False
	standardize:True
	add_noise:False
	noise_params:None
	dataset:qm_benchmark
	}
	model:qDict{
	name:None
	num_blocks:4
	hidden_channels:128
	out_channels:1
	int_emb_size:64
	basis_emb_size:16
	out_emb_channels:256
	num_spherical:8
	num_radial:6
	envelope_exponent:5
	max_num_neighbors:32
	cutoff:5.0
	num_before_skip:1
	num_after_skip:2
	num_output_layers:3
	}
	dataloader:{'batch_size': 256, 'eval_batch_size': 256, 'num_workers': 8, 'pin_memory': True}
	optim:qDict{
	optimizer:AdamW
	optimizer_params:{'weight_decay': 0.0001}
	lr_initial:0.0008
	scheduler:LambdaLR
	scheduler_params:{'lambda_type': 'cosine', 'warmup_factor': 0.2, 'warmup_epochs': 0.01, 'lr_min_factor': 0.01}
	clip_grad_norm:10
	max_epochs:500
	energy_coefficient:1
	force_coefficient:20
	loss_energy:mae
	loss_force:mae
	ema:False
	ema_decay:0.999
	eval_every:5000
	}
	ckp_file:None
	test:False
	distributed:False
	rank:0
	device:cuda
	}
2024-12-24 11:57:31,148 - filelogger.py:78 - qDict{
	seed:377
	log_dir:logs/dimenetpp_qmbenchmark/baseline_e/
	print_freq:100
	config_file:logs/dimenetpp_qmbenchmark/baseline_e/config.yaml
	init_file:None
	task:qDict{
	data_key:None
	data_root:/root/proj/database/qm_benchmark
	target:energy
	regress_force:False
	standardize:True
	add_noise:False
	noise_params:None
	dataset:qm_benchmark
	}
	model:qDict{
	name:None
	num_blocks:4
	hidden_channels:128
	out_channels:1
	int_emb_size:64
	basis_emb_size:16
	out_emb_channels:256
	num_spherical:8
	num_radial:6
	envelope_exponent:5
	max_num_neighbors:32
	cutoff:5.0
	num_before_skip:1
	num_after_skip:2
	num_output_layers:3
	}
	dataloader:{'batch_size': 256, 'eval_batch_size': 256, 'num_workers': 8, 'pin_memory': True}
	optim:qDict{
	optimizer:AdamW
	optimizer_params:{'weight_decay': 0.0001}
	lr_initial:0.0008
	scheduler:LambdaLR
	scheduler_params:{'lambda_type': 'cosine', 'warmup_factor': 0.2, 'warmup_epochs': 0.01, 'lr_min_factor': 0.01}
	clip_grad_norm:10
	max_epochs:500
	energy_coefficient:1
	force_coefficient:20
	loss_energy:mae
	loss_force:mae
	ema:False
	ema_decay:0.999
	eval_every:5000
	}
	ckp_file:None
	test:False
	distributed:False
	rank:0
	device:cuda
	}
2024-12-24 11:58:29,398 - filelogger.py:78 - qDict{
	seed:377
	log_dir:logs/dimenetpp_qmbenchmark/baseline_e/
	print_freq:100
	config_file:logs/dimenetpp_qmbenchmark/baseline_e/config.yaml
	init_file:None
	task:qDict{
	data_key:None
	data_root:/root/proj/database/qm_benchmark
	target:energy
	regress_force:False
	standardize:True
	add_noise:False
	noise_params:None
	dataset:qm_benchmark
	}
	model:qDict{
	name:None
	num_blocks:4
	hidden_channels:128
	out_channels:1
	int_emb_size:64
	basis_emb_size:16
	out_emb_channels:256
	num_spherical:8
	num_radial:6
	envelope_exponent:5
	max_num_neighbors:32
	cutoff:5.0
	num_before_skip:1
	num_after_skip:2
	num_output_layers:3
	}
	dataloader:{'batch_size': 256, 'eval_batch_size': 256, 'num_workers': 8, 'pin_memory': True}
	optim:qDict{
	optimizer:AdamW
	optimizer_params:{'weight_decay': 0.0001}
	lr_initial:0.0008
	scheduler:LambdaLR
	scheduler_params:{'lambda_type': 'cosine', 'warmup_factor': 0.2, 'warmup_epochs': 0.01, 'lr_min_factor': 0.01}
	clip_grad_norm:10
	max_epochs:500
	energy_coefficient:1
	force_coefficient:20
	loss_energy:mae
	loss_force:mae
	ema:False
	ema_decay:0.999
	eval_every:5000
	}
	ckp_file:None
	test:False
	distributed:False
	rank:0
	device:cuda
	}
